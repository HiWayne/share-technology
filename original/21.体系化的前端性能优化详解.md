# 21.体系化的前端性能优化详解（未完待续……）

性能优化这个词我们经常会在前端的工作或面试中遇到，这个东西说难好像也并不怎么难，毕竟谁都能说上几点。但是如果你想在工作上遇到各种场景的性能瓶颈时都有直击本质的性能方案，或者在面试时让面试官眼前一亮，那就不能只拘泥于『想到哪说到哪』，而要有一套体系化的、各个角度的知识图谱。这篇文章也算对我个人的前端知识的一次归纳总结，因为『性能优化』不仅仅是『优化』，什么意思呢？优化之前，首先要知道为什么要这样优化，这就需要你对上到框架、js，下到浏览器、网络等等的原理都有不错的了解。所以性能优化真的涵盖了太多前端知识。

首先我们来谈一谈前端性能的本质，前端的输出物是一个网络应用，应用的性能好坏是它的运行效率决定的，前面再加上网络那就是再和网络效率有关。所以前端性能的本质就是网络性能和运行性能。所以前端性能优化体系中的两大分类我认为就是：网络、运行。

# 网络层面

如果我们把网络比做一根水管，前端应用是对面手上的一杯水，你现在想更快接完对面的水，无非就两点：1. 让水管流量变大；2. 让对面杯子里的水变少。水管流量也就是网络带宽，杯子水变少就是比如缓存、压缩、代码分割等等手段。

先说网络，网络不仅由用户的运营商决定，也可以通过网络协议优化其效率。

计算机网络理论上是 OSI 七层模型，实际可以看成五层（或四层模型），分别是物理层、数据链路层、网络层、传输层、应用层，每一层封装解析自己的协议，负责各自的职责，将上层数据交给上层处理。我们主要关注应用层和传输层。

## TCP 协议的优化

先总结一下常见的优化方法，具体的 tcp 原理之后介绍。

1. 首个资源大小不要超过 14kb，可以高效利用 tcp 的慢启动

- 假设 tcp 初始窗口是 10、`MSS`是 1460，那么第一个请求的资源大小就不要超过 14600 字节，也就是大概 14kb。这样对端的 tcp 一次性就可以发送完，否则至少分 2 次发送，第二次要等第一次的 ack。

2. 频繁发送小数据包（小于 MSS）导致 tcp 阻塞怎么办？

- 关闭`Nagel`算法
- 避免延迟 ack

3. 如何优化 tcp 丢包重传

- 通过`net.ipv4.tcp_sack`打开`SACK`（默认开启）
- 通过`net.ipv4.tcp_dsack`打开`D-SACK`（默认开启）

`以下的 tcp 优化一般发生在服务端`，和前端相关的比如前端写的 node 服务、前端页面并发等等。

1. 服务端收到的请求并发量太高或遭遇 SYN 攻击，导致 SYN 队列占满，无法再响应请求

- 使用`syn cookie`
- 减少 syn ack 重试次数
- 增加 syn 队列大小

2. TIME-WAIT 数量太多导致可用端口被占满，无法再发送请求

- 使用操作系统的`tcp_max_tw_buckets`配置，控制并发的 TIME-WAIT 数量
- 如果可以的话，增加客户端或服务端的端口范围和 ip 地址

以上的 tcp 优化方法是在了解 tcp 机制的基础上，调整操作系统参数，可以一定程度上实现网络性能优化。下面我们将从 tcp 的实现机制讲起，然后解释清楚这些优化手段到底做了什么。

我们都知道 tcp 传输前要先建立连接，但实际上网络传输是不需要建连的，网络在设计之初要求的特点就是突发性、随时发送，所以摈弃了电话网那样的设计。平时 t 所谓的 tcp 连接，其实只是两台设备之间保存彼此通信的一些状态，并不是真正意义上的连接。tcp 需要通过五元组区分是否是同一个连接，其中有一个元组是协议，剩下四个是，`src_ip、src_port、dst_ip、dst_port`（双端 ip 和端口号）。另外 tcp 报文段的首部有四个重要的东西，`Sequence Number`是包的序号(seq)，表示这个 packet 的数据部分的第一位应该在整个 data stream 中所在的位置，用来解决网络包乱序问题。`Acknowledgement Number`(ack)表示的是这次收到的数据长度 + 这次收到的 seq，同时也是对方（发送方）的下一次 sequence number，用于确认收到，解决不丢包的问题。`Window`又叫 Advertised-Window，是滑动窗口，用于实现流量控制的。`TCP Flag`是包的类型，比如`SYN`、`FIN`、`ACK`这些，主要是用于操控 TCP 的状态机。

**下面详细介绍一下 tcp 的原理**：

### tcp 三次『握手』

三次握手的本质是为了知道双方的初始序列号、MSS、窗口等信息，这样才能在乱序情况下有序拼接数据、以及探明网络、硬件的最大承载能力等。

初始 seq 序列号（`ISN`）32 位，由虚拟时钟以 4 微秒的频率不断+1 生成，超过 2^32 又回到 0，循环一次需要 4.55 小时。之所以每次建连不固定从 0 开始，是为了避免断线重新建连后，新包和延迟到达的旧包 seq 冲突的问题。4.55 小时已超出 Maximum Segment Lifetime(`MSL`)，旧包已经不存在了。

1. 客户端发出 SYN（flags: SYN）包，假设初始 seq 是 x，所以 seq = x。客户端 tcp 进入 `SYN_SEND` 状态。
2. 服务端 tcp 初始是 `LISTEN` 状态，收到后发送 ACK 包（flags: ACK, SYN），假设初始 seq 是 y，seq = y，ack = x + 1 ，这是因为 flags 有 SYN，占用 1 个长度，所以接下来客户端应该从 x + 1 开始。服务端进入 `SYN_RECEIVED` 状态。
3. 客户端收到后发送 ACK 包，seq = x + 1，ack = y + 1。然后继续发送实际内容的 PSH 包（假设数据长度是 100），seq = x + 1，ack = y + 1。实际内容的 seq、ack 之所以和 ack 包没有变化是因为 Flag 是 ACK 仅用作确认，本身不占用长度。客户端进入 `ESTABLISHED` 状态。
4. 服务端收到后发送 ACK 包，seq = y + 1，ack = x + 101。服务端进入 `ESTABLISHED` 状态。

seq、ack 的计算可以对照这个抓包图（图片来自网络，其中的序列号是相对序号）

![tcp发送过程](https://segmentfault.com/img/remote/1460000016375114/view)

### SYN 超时与攻击

服务端在三次握手时，收到 SYN 包、回了 SYN-ACK 后，tcp 处于半连接的中间状态，操作系统内核会将连接暂时放进 SYN 队列，三次握手成功后才会将连接放入完全连接的队列。如果服务端没有收到来自 client 的 ACK，会超时重试，默认重试 5 次，从 1s 开始翻倍，1s、2s、4s……知道第 5 次也超时一共需要 63s，这时 tcp 会断掉这个连接。有些攻击者会利用这个特性，大量对服务端发送 SYN 包然后断开，服务端要等 63s 才将连接从 SYN 队列清除，从而导致服务端 tcp 的 SYN 队列占满，无法再继续提供服务。正常的大并发情况下也可能出现这种情况。这时我们可以在 linux 下设置以下参数：

1. `tcp_syncookies`，它可以在 SYN 队列满了之后将四元组信息、每 64s 递增一次的时间戳、MSS 选项值生成一个特别的 Sequence Number(也叫 cookie)，将这个 cookie 作为 seq 发送给 client 则可以直接建连。tcp_syncookies 通过这种巧妙的方式不需要在本地就保存了 SYN 里的部分信息。细心的观众会发现，tcp_syncookies 似乎只需要两次握手就可以建连了，为什么不把它纳入 tcp 标准呢？因为它也是有缺点的，1. MSS 的编码只有 3 位，因此最多只能使用 8 种 MSS 值。2. 服务端必须拒绝客户端 SYN 报文中的其他只在 SYN 和 SYN+ ACK 中协商的选项，原因是服务端没有地方可以保存这些选项，比如 Wscale 和 SACK。3. 增加了密码学运算。所以在因为正常并发大而出现 SYN 队列满的情况时，不要使用这种方式，它只是一个阉割版的 tcp。

2. `tcp_synack_retries`，用它减少 SYN-ACK 超时的重试次数，也就减少了 SYN 队列的清理时间。

3. `tcp_max_syn_backlog`，增加最大 SYN 连接数，也就是增大 SYN 队列。

4. `tcp_abort_on_overflow`，SYN 队列满就拒绝连接。

### tcp 四次『挥手』

假设是客户端先断开连接，举例的 seq 接着上次的握手。

关闭前两端的 tcp 状态都是 `ESTABLISHED`。

1. 客户端发出 FIN 包（flags: FIN）表示可以关闭，seq = x + 101, ack = y + 1。客户端变为 `FIN-WAIT-1` 状态。
2. 服务端收到这个 FIN，返回一个 ACK，seq = y + 1，ack = x + 102。服务端变为 `CLOSE-WAIT` 状态。客户端收到这个 ACK 后变为 `FIN-WAIT-2` 状态。
3. 服务端可能有一些工作未做完，做完后也发送 FIN 包决定关闭，seq = y + 1，ack = x + 102。服务端变为 `LAST-ACK` 状态。
4. 客户端收到 FIN 后返回确认 ACK，seq = x + 102，ack = y + 2。客户端变为 `TIME-WAIT` 状态
5. 服务端收到客户端 ACK 后直接关闭连接，变为 `CLOSED` 状态。客户端等待 2\*MSL 时间后没有再次收到服务端的 FIN，则关闭连接，变为 `CLOSED` 状态。

为何需要长时间的 `TIME-WAIT`？1. 可以避免复用该四元组的新连接接收到延迟的旧包 2. 可以确保服务端已经关闭

为何 `TIME-WAIT` 的时间是 2\*MSL（最大 segment 存活时间，[RFC793](https://www.rfc-editor.org/rfc/rfc793) 定义了 MSL 为 2 分钟，Linux 设置成了 30s）？因为服务端在发送 FIN 后，如果等待 ACK 超时了会重发，FIN 最长存活 MSL 时间，重发一定发生在这之前，重发的 FIN 也是最长存活 MSL 时间。所以 2 倍的 MSL 时间后，客户端依然没有收到服务端的重发，说明服务端已经收到 ACK 关闭了，所以客户端就可以关闭了。

### 断连产生的 TIME-WAIT 数量太多怎么办

我们知道在 linux 里默认会等待 1 分钟才关闭连接，这时端口一直是被占用的状态。如果在大并发的短连接下，可能会出现 `TIME-WAIT` 数量过多导致端口被占满或者 cpu 占用过大的情况。

**前两个配置强烈建议不要用**

1. `tcp_tw_reuse`，必须在客户端和服务端都开启 timestamp 才可使用，仅在客户端生效。开启后不用等待 TIME-WAIT，仅需 1s，新连接可以直接复用这个 socket。为什么需要开启 timestamp？因为旧连接的包可能兜兜转转终于到达了服务端，而复用该 socket 的新连接五元组和旧包是一样的，只要时间戳早于新包的肯定是旧连接的包，可以避免无用的旧包被误接受。

2. `tcp_tw_recycle`，tcp_tw_recycle 处理更激进，它会快速回收 TIME_WAIT 状态的 socket 。只有当 tcp_timestamps 和 tcp_tw_recycle 都开启时，才会快速回收。当客户端通过 NAT 环境访服务器端时，服务器端主动关闭后会产生了 TIME_WAIT 状态，如果服务器端同时开启了 tcp_timestamps 和 tcp_tw_recycle 选项时，那么在 60 秒内来自同一源 IP 主机的 TCP 分段的时间戳必须递增，否则会丢弃。Linux 从 4.12 内核版本开始移除了 tcp_tw_recycle 配置。

3. `tcp_max_tw_buckets`，控制并发的 TIME-WAIT 的数量，默认值是 180000，如果超过，系统会销毁并记录 log

4. `ip_local_port_range`，增加客户端端口范围

5. 如果可能的话，增加服务端的服务端口

6. 如果可能的话，增加客户端或服务端的 ip

### tcp 滑动窗口与流量控制

操作系统给 tcp 开辟了一个缓存区，限制了 tcp 的最大收发数据包数量，可以形象的把它看作滑动的`Window`。发送端的叫发送窗口`swnd`，接收方的叫接收窗口`rwnd`。已发送但未收到 ack 的数据长度 + 待发送的缓存数据长度 = 发送窗口总长度。

![发送窗口](https://cdn.jsdelivr.net/gh/xiaolincoder/ImageHost2/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/TCP-%E5%8F%AF%E9%9D%A0%E7%89%B9%E6%80%A7/19.jpg)

握手时双端交换窗口值，最终会取其中的最小值。假设发送方窗口大小是 20，一开始发了 10 个包，还没有收到 ack，于是后续只能再放 10 个包进入缓存区。如果缓存区被占满了，就无法再发送数据了。接收方接收到数据也是放进缓存区，如果处理能力小于对端的发送能力，缓存区越堆越多，可用接收窗口也就变小了，ack 携带的窗口值会让发送方减少发送的数据量。此外，操作系统也会调整缓冲区的大小，这时可能发生一种情况，本来可用接收窗口是 10，已经通过 ack 告诉对端了，但是操作系统突然缩小了缓冲区，窗口减少 15，反而倒欠了 5 个。发送端前面收到了可用窗口是 10，于是依然会发送数据，但是数据无法被接收方处理，于是超时了。为了避免这种情况，tcp 强制规定，如果操作系统要修改缓冲区，必须提前先发送修改后的可用窗口。

我们通过上面的内容知道，tcp 是通过两端的窗口来限制发送流量的，如果窗口是 0 就代表应该暂时停止发送了。当接收方缓冲区满发送窗口为 0 的 ack 后，经过一段时间接收方有能力接收了，就会发一个窗口非 0 的 ack 通知发送方继续发送。如果这个 ack 丢了就会很严重，发送方一直不知道接收方可以接收了，就会一直等待，进入死锁情况。为了避免这个问题，tcp 的设计是，发送方在被通知停止发送后（也就是收到窗口 0 的 ack），会启动一个定时器，每隔 30-60 秒会发一个窗口探测 ( Window probe ) 报文，接收方收到后要回复当前的窗口。如果连续 3 次窗口探测都是 0 的话，有些 tcp 的实现里会发送`RST`包中断连接。

如果接收方窗口已经很小了，发送方依然会利用这点窗口发送数据，tcp 头 + ip 头 40 字节，可能数据就几字节，那就非常的不划算。怎么避免这种情况呢？下面看看小数剧包如何优化。

### tcp 小数据包

对于接收方，只要不让它发送小窗口就行，接收方通常才有这种策略：接收窗口如果小于`MSS、缓存空间/2`的最小值，就告知对端窗口是 0，不要再发数据了，直到窗口大于那个条件。

对于发送方，使用 `Nagle` 算法，只有满足以下两个条件的其一才会发送：

- 窗口大小 >= `MSS` 并且 总数据大小 >= `MSS`
- 收到之前发送数据的 ack

如果一条都没满足，它就会一直积攒数据，然后达到某个条件一起发送。

伪代码如下

```shell
if there is new data to send then
    if the window size ≥ MSS and available data is ≥ MSS then
        send complete MSS segment now
    else
        if there is unconfirmed data still in the pipe then
            enqueue data in the buffer until an acknowledge is received
        else
            send data immediately
        end if
    end if
end if
```

`Nagle` 算法默认是打开的，但是在例如`ssh`这种数据小、交互多的场景下，`Nagle` 碰上延迟 ack 会很糟糕，所以需要关闭。（`Nagle` 算法没有系统全局配置，需要根据各自应用关闭）

说完小数据优化，现在再说回滑动窗口，其实 tcp 最终采用的窗口并不完全由滑动窗口决定，滑动窗口只是防止双端超出收发能力，还要考虑两端之间的网络情况，如果两端收发能力都很强，但此刻网络环境很差，发大量数据只会让网络更拥堵，所以还有一个拥塞窗口，tcp 会取滑动窗口和拥塞窗口的最小值。

### tcp 慢启动与拥塞避免

首先要讲一下什么是 `MSS`，`MSS` 是一个 tcp segment 最大允许的数据字节长度，是由 `MTU`（数据链路层最大数据长度，由硬件规定的）减去 ip 头 20 字节 减去 tcp 头 20 字节算出来的，一般是 1460。也就是代表一个 tcp 包最多携带 1460 字节上层的数据。tcp 握手时会在双端协商出最小的 MSS。在实际网络环境中，请求会经过很多中间设备，SYN 里的 MSS 还会被它们修改，最终会是整个路径中的最小值，而不仅仅是两端的最小值。

tcp 有一个`cwnd`（拥塞窗口）负责避免网络拥塞，它的值是整数倍 tcp 报文段大小，代表 tcp 一次性能发多少个包（为了方便起见我们从 1 开始表示它），它的初始值很小，会逐步增加直至发生丢包重传，以此探测可用网络传输资源。在经典慢启动算法中，快速确认模式下，每次成功收到确认 ack，会让`cwnd` + 1，因此`cwnd`呈指数级增长，1、2、4、8、16……直到达到慢启动阈值 `ssthresh` （`slow start threshold`），ssthresh 一般等于 max(在外数据值/2, 2\*`SMSS`)，`SMSS`是发送方的最大段大小。当`cwnd` < `ssthresh`时使用的叫`慢启动算法`，当`cwnd` >= `ssthresh`时使用`拥塞避免算法`。

`拥塞避免算法`，在每次收到确认 ack 后，`cwnd`会增加`1/cwnd`，即上次发出的包全部确认，cwnd + 1。不同于`慢启动算法`，`拥塞避免算法`是线性增长，直到发生两种重传后下降，1. 发生超时重传、2. 发生快速重传。

### 快速/延迟 ack、超时重传与快速重传

快速确认模式是接收方收到包后立刻发送确认 ack，但 tcp 不会每次都收到一个包就返回确认 ack，这样对网络带宽是一种浪费。tcp 还可能进入延迟确认模式，接收端会启动延迟 ack 定时器，每隔 200ms 检查是否要发送 ack，如果有数据要发送，也可以和 ack 合并在一起。假设发送方一次性发了多个包，对端可能不会回复 10 个 ack，只会回复已收到的最大连续包的最后一个的 ack。比如传了 1、2、3，……10，接收端全部收到了，于是回复 10 的 ack，这样发送端就知道前 10 个全部接收了，于是下一个从 11 发起。如果中间有丢包的，就返回丢包的前一个的 ack。

**超时重传**：发送方发送后会启动一个定时器，超时时间(`RTO`)适合设置为略大于一个`RTT`(包往返时间)，如果接收 ack 超时了，会重新发送数据包，如果重发的数据又超时了，超时计时会加倍。这时`ssthresh`变成`cwnd/2`、`cwnd`重置为初始值，使用`慢启动算法`。可以看到`cwnd`断崖式下降，所以发生超时重传对网络性能影响很大。那是不是一定要等`RTO`才能重传呢？

**快速重传**：tcp 有一个快速重传的设计，接收方如果没有按序收到包，就回一次最大连续的那个 ack，发送方连续收到 3 次这样的 ack 就认为丢包了，可以快速把那个包重传一次而不回退到慢启动。举个例子，接收方收到了 1、2、4，于是回 2 的 ack，后面又接收到了 5、6，因为中间断了 3，所以还是回了两次 2 的 ack。发送端连续收到 3 次相同的 ack，于是知道 3 丢了，快速重传了 3。接收方收到 3，数据连续了，于是返回 6 的 ack，发送方就可以接着从 7 开始传了。就像下图所示：

![tcp快速重传](https://pdai.tech/images/develop/network/dev-network-tcpip-7.png)

发生快速重传会：

1. `ssthresh` = `cwnd/2`、`cwnd` = `ssthresh + 3`，开始重传丢失的包，进入快速恢复算法。+3 的原因是收到了 3 个重复的 ack，表明当前网络至少还能正常额外收发这 3 个包。
2. 再收到重复的 ACK 时，拥塞窗口增加 1
3. 当收到新的数据包的 ACK 时，把 cwnd 设置为第一步中的 ssthresh 的值。

快速重传算法首次出现在 4.3BSD 的 Tahoe 版本，快速恢复首次出现在 4.3BSD 的 Reno 版本，也称之为 Reno 版的 TCP 拥塞控制算法。
可以看出 Reno 的快速重传算法是针对一个包的重传情况的，然而在实际中，一个重传超时可能导致许多的数据包的重传，因此当多个数据包从一个数据窗口中丢失时并且触发快速重传和快速恢复算法时，问题就产生了。因此 NewReno 出现了，它在 Reno 快速恢复的基础上稍加了修改，可以恢复一个窗口内多个包丢失的情况。具体来讲就是：Reno 在收到一个新的数据的 ACK 时就退出了快速恢复状态了，而 NewReno 需要收到该窗口内所有数据包的确认后才会退出快速恢复状态，从而更一步提高吞吐量。

### tcp 如何『精准』重传

如果出现了部分丢包的情况，发送方不知道究竟是哪些丢了部分还是全部丢了。比如接收端收到了 1、2，4，5, 6，发送端可以通过 ack 知道 3 以后的丢包了，触发快速重传。这时会有两种决策：1. 只重传第 3 个包。2. 不知道 4, 5, 6……是不是也丢包了，于是干脆把 3 以后的全部重传。这两种选择都不太好，如果只重发 3，万一后面真的也都丢了，每一个都得继续等待重传。但是如果直接全部重传，万一真的只有 3 丢了，也比较浪费，该怎么优化呢？

快速重传只是减少了触发超时重传的机会，无论快速重传还是超时重传都没有解决精确知道到底要重传一个还是全部的问题。还有一种更好的方法叫`选择性确认 Selective Acknowledgment (SACK)`，它需要双端都支持，Linux 通过`net.ipv4.tcp_sack`参数开关。`SACK`会在 tcp 头里增加一段数据，告诉发送方除了最大连续的之外还收到了哪些数据段，这样发送方就知道那些数据可以不用重传了。一图胜千言：

![SACK](https://cdn.jsdelivr.net/gh/xiaolincoder/ImageHost2/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/TCP-%E5%8F%AF%E9%9D%A0%E7%89%B9%E6%80%A7/11.jpg)

另外还有`Duplicate SACK`(`D-SACK`)。如果接收方的确认 ACK 丢包了，发送发会误以为接收方没收到，触发超时重传，这时接收方会收到重复数据。或者由于发送包遇到网络拥堵了，重传的包比之前的包更早到达，接收方也会收到重复数据。这时可以在 tcp 头里加一段`SACK`数据，值是重复的数据段范围，因为数据段小于 ack，发送端就知道这些数据接收方已经收过了，不会再重传。

![D-SACK](https://cdn.jsdelivr.net/gh/xiaolincoder/ImageHost2/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/TCP-%E5%8F%AF%E9%9D%A0%E7%89%B9%E6%80%A7/12.jpg)

`D-SACK`在 Linux 中通过`net.ipv4.tcp_dsack`参数开关。

总结一下`SACK`和`D-SACK`的作用就是：让发送方知道哪些包没收到、是否重复收包，可以判断出是数据包丢了、还是 ack 丢了、还是数据包被网络延迟了、还是网络中把数据包复制了。

## http 协议的优化

1. 在 HTTP/1.1 下要避免达到浏览器同域名请求最大并发限制（chrome 一般是 6 个）

- 页面资源请求数较多时，可以准备多个域名
- 多个小图标可以合并到一张大图里，前端通过 css 的`background-position`样式展示对应图标（也称雪碧图）

2. 减少 HTTP header 大小

- 同 domain 的请求会自动携带 cookie，不需要身份验证的资源尽量不要和站点同 domain。

3. 合理利用 HTTP 缓存。缓存可以直接省去请求，对网络性能提升巨大。

- 客户端使用`cache-control`的`no-cache`、`max-stale`等控制是否使用强缓存、协商缓存、缓存过期是否依然可用等功能。
- 服务端通过`cache-control`的`max-age`、`public`、`stale-while-revalidate`等控制强缓存时间、是否能被代理服务端缓存、缓存过期多久能自动刷新缓存等功能。

4. 升级到 HTTP/2.0 或更高版本。（必须使用 TLS）

5. 对 HTTPS 优化

HTTPS 产生性能消耗的两个环节：

第一个环节， TLS 协议握手过程；
第二个环节，握手后的对称加密报文传输。
对于第二环节，现在主流的对称加密算法 AES、ChaCha20 性能都是不错的，而且一些 CPU 厂商还针对它们做了硬件级别的优化，因此这个环节的性能消耗可以说非常地小。

而第一个环节，TLS 协议握手过程不仅增加了网络延时（最长可以花费掉 2 RTT），而且握手过程中的一些步骤也会产生性能损耗，比如：

对于 ECDHE 密钥协商算法，握手过程中会客户端和服务端都需要临时生成椭圆曲线公私钥；
客户端验证证书时，会访问 CA 获取 CRL 或者 OCSP，目的是验证服务器的证书是否有被吊销；
双方计算 Pre-Master，也就是对称加密密钥；
为了清楚这些步骤在 TLS 协议握手的哪一个阶段，可以参考这幅图：

![TSL握手](https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost4@main/%E7%BD%91%E7%BB%9C/https%E4%BC%98%E5%8C%96/tls%E6%80%A7%E8%83%BD%E6%8D%9F%E8%80%97.png)

- 硬件优化：服务器使用支持 AES-NI 指令集的 CPU
- 软件优化：升级 Linux 版本、TSL 版本。TSL/1.3 大幅优化了握手次数，只需要 1RTT，而且支持前向安全性。
- 证书优化：`OCSP Stapling`，正常情况下浏览器是需要向 CA 验证证书是否被吊销的，而服务器可以向 CA 周期性地查询证书状态，获得一个带有时间戳和签名的响应结果并缓存它。当有客户端发起连接请求时，服务器会直接把这个「响应结果」在 TLS 握手过程中发给客户端。
- 会话复用 1：`Session ID`，双方在内存里保留 session，下一次建立连接时 hello 消息里会带上 Session ID，服务器收到后就会从内存中找，如果找到就直接用该会话密钥恢复会话状态，跳过其余的过程。为了安全性，内存中的会话密钥会定期失效。但是它有两个缺点：1. 服务器必须保持每一个客户端的会话密钥，随着客户端的增多，服务器的内存压力也会越大。2. 现在网站服务一般是由多台服务器通过负载均衡提供服务的，客户端再次连接不一定会命中上次访问过的服务器，于是还要走完整的 TLS 握手过程。
- 会话复用 2：`Session Ticket`，客户端与服务器首次建立连接时，服务器会加密「会话密钥」作为 Ticket 发给客户端，交给客户端缓存该 Ticket，类似验证用户身份的 token 方案。客户端再次连接服务器时，客户端会发送 Ticket，服务器解密后就可以获取上一次的会话密钥，然后验证有效期，如果没问题，就可以恢复会话了，开始加密通信。对于集群服务器的话，要确保每台服务器加密 「会话密钥」的密钥是一致的，这样客户端携带 Ticket 访问任意一台服务器时，都能恢复会话。

`Session ID` 和 `Session Ticket` 都不具备前向安全性，因为一旦加密「会话密钥」的密钥被破解或者服务器泄漏「会话密钥」，前面劫持的通信密文都会被破解。同时应对重放攻击也很困难，所谓的重放攻击就是，假设中间人截获了 post 请求报文，虽然他无法解密其中的信息，但他重复使用该非幂等报文对服务器请求，依然可以在用户不知情下篡改数据库信息。减少重放攻击的影响可以将对会话密钥的加密设定一个合理的过期时间。

下面是对 http 知识点的详细介绍。

### HTTP/0.9

最初的版本非常简单，目的是为了快速推广使用，功能也只是简单的 get html，请求写法如下：

```
GET /index.html
```

### HTTP/1.0

随着互联网发展，为了应对更多功能，有了我们熟悉的 http header、状态码、`GET` `POST` `HEAD`请求方式、缓存等，还能传输图片、视频等二进制文件。

缺点是每次请求完都会断开连接，下一次 http 请求需要 tcp 重新建连。于是有些浏览器增加了非标准的`Connection: keep-alive`头，服务器也会回复相同的头，用来让 tcp 保持长连接，后面的 http 请求可以复用这个 tcp，直到某一方主动关闭。

### HTTP/1.1

1.1 版本是目前使用最广泛的，在这个版本默认使用 tcp 长连接，如果要关闭需添加头`Connection: close`。

另外它还有管道机制(`pipelining`)，客户端可以在同一个 tcp 里可以不需要等待返回连续发多个 http 请求。而之前版本的协议只能发送一个，收到返回值以后才能再发送下一个。但 1.1 在服务端依然只能按`FIFO`的处理顺序发出响应，所以响应时还是会被队首 http 阻塞。连续多个响应在接受时可以通过`Content-Length`划分。

还新增了分块传输编码（`chunked transfer encoding`），以流的形式代替 buffer 形式，比如一个视频，不需要完整把它读到内存然后再发送了，可以通过 stream 读一小部分就发一小部分。使用`Transfer-Encoding: chunked`头开启，每个分块前面会有一个 16 进制的数代表这个分块的长度，如果数字是 0 代表分块发送完了。在大文件传输或文件处理等场景，使用这一特性可以提高效率、减少内存占用。

这个版本有以下几个缺点：

1. 队头阻塞。必须请求-响应才算一次 http 结束，如果前一个 http 慢了，会影响下一个的发送时间。同时浏览器对同一域名的 http 请求有最大并发限制，超出就必须等待前面的完成。
2. http 头冗余。每次 http 请求头基本一样，浪费网络资源。

其实 http1.1 的缺点本质上是它的定位是一个纯文本协议导致的。如果想做乱序发送，要么修改协议本身，在请求/响应里添加个唯一标识，然后做文本的解析。要么对 http 协议再做一层封装，将文本二进制数据进一步封装处理。显然后者更合理一点。于是 http/2.0 里会把原数据分割成二进制帧的形式，方便做更细粒度的操作。

### HTTP/2.0

新增的性能改进不仅包括 HTTP/1.1 中已有的多路复用，修复队头阻塞问题，允许设置设定请求优先级，还包含了一个头部压缩算法（HPACK）。此外， HTTP/2 采用了二进制而非明文来打包、传输客户端和服务器之间的数据。

#### 帧、消息、流和 TCP 连接

我们可以把 2.0 版本看作在 http 之下又加了一个二进制分帧层。`消息(message)`（一个完整的请求或响应）被分成很多`帧(frame)`，帧包含部分：类型 `Type`, 长度 `Length`, 标记 `Flags`, 流标识 `Stream` 和有效载荷 `frame payload`。同时还增加了`流`这个抽象的概念，每帧的流标识代表它属于哪个流，发送/接受方根据标识将乱序发送的数据组装起来。为了防止两端流 ID 冲突，客户端发起的流具有奇数 ID，服务器端发起的流具有偶数 ID。原先协议的内容不收影响，http1.1 中的首部信息 header 封装到 Headers 帧中，而 request body 将被封装到 Data 帧中。多个请求只使用一个 tcp 通道。这个举措在实践中表明，相比 HTTP/1.1，新页面加载可以加快 11.81%到 47.7%

#### HPACK 算法

HPACK 算法是 HTTP/2 新引入的一个算法，用于对 HTTP 头部做压缩。其原理在于：

- 客户端与服务端根据 [RFC 7541](https://tools.ietf.org/html/rfc7541) 的附录 A，维护一份共同的静态字典（Static Table），其中包含了常见头部名及常见头部名称与值的组合的代码；
- 客户端和服务端根据先入先出的原则，维护一份可动态添加内容的共同动态字典（Dynamic Table）；
- 客户端和服务端根据 [RFC 7541](https://tools.ietf.org/html/rfc7541) 的附录 B，支持基于该静态哈夫曼码表的哈夫曼编码（Huffman Coding）。

#### 服务器推送

以往浏览器要额外获取服务器数据，需要主动发起请求。这就必须在网站中加入额外的脚本，并等待 js 加载完调用。这就导致请求时机的阻塞延后、多余的 request、低效繁琐的开发体验。HTTP/2 支持了服务端主动推送，不需要浏览器主动发请求，节约了请求效率、也优化了开发体验。

### HTTP/3.0

HTTP/2.0 相比前任做出了大量的优化，比如多路复用、头部压缩等等，但因为基于 tcp 导致有些痛点是难以解决的。

#### 队头阻塞

HTTP 是运行在 TCP 之上的，虽然二进制分帧已经可以做到多个请求不阻塞了，但大家通过上面讲到 TCP 原理很容易就知道，TCP 中的也有队头阻塞和重传，如果前面的包 ack 没有回来，后面的是不会发送的。所以 HTTP/2.0 只是解决了 HTTP 层面的队头阻塞，在整个网络链路中依然是阻塞的。

#### TCP、TSL 握手的延迟

TCP 有 3 次握手，TSL（1.2）有 4 次握手，一共需要 3 个 RTT 时延才能发出请求。同时因为 TCP 的拥塞避免是会慢启动的，所以还会进一步拖慢速度。

#### 切换网络导致重新连接

我们知道 TCP 连接的唯一性是根据双端 ip、端口来的。现在移动网络、交通都非常发达，进办公室手机自动连上 WIFI，在地铁、高铁上手机网络十几秒换一个基站是很常见的场景。它们都会导致 ip 变化，从而让之前的 TCP 连接失效。

#### QUIC 协议

上述的问题是 TCP 固有的，要想解决只能重新换一个协议，那就是 QUIC。完全新的协议是需要硬件支持的，这必然需要非常久的时间普及，于是 QUIC 建立在已有的一个协议`UDP`之上。

QUIC 协议的优点有很多，比如：

#### 无队头阻塞

QUIC 协议也有类似 HTTP/2 Stream 与多路复用的概念，也是可以在同一条连接上并发传输多个 Stream，一个 Stream 可以认为就是一条 HTTP 请求。

由于 QUIC 使用的传输协议是 UDP，UDP 不关心数据包的顺序，如果数据包丢失，UDP 也不关心。

不过 QUIC 协议还是要保证数据包的可靠性，每个数据包都有一个序号唯一标识。当某个流中的一个数据包丢失了，即使该流的其他数据包到达了，数据也无法被 HTTP/3 读取，直到 QUIC 重传丢失的报文，数据才会交给 HTTP/3。

而其他流的数据报文只要被完整接收，HTTP/3 就可以读取到数据。这与 HTTP/2 不同，HTTP/2 只要某个流中的数据包丢失了，其他流也会因此受影响。

所以，QUIC 连接上的多个 Stream 之间并没有依赖，都是独立的，某个流发生丢包了，只会影响该流，其他流不受影响。

#### 更快的连接建立

对于 HTTP/1 和 HTTP/2 协议，TCP 和 TLS 是分层的，分别属于内核实现的传输层、OpenSSL 库实现的表示层，因此它们难以合并在一起，需要分批次来握手，先 TCP 握手，再 TLS 握手。

HTTP/3 在传输数据前虽然需要 QUIC 协议握手，这个握手过程只需要 1 RTT，握手的目的是为确认双方的「连接 ID」，连接迁移就是基于连接 ID 实现的。

但是 HTTP/3 的 QUIC 协议并不是与 TLS 分层，而是 QUIC 内部包含了 TLS，它在自己的帧会携带 TLS 里的“记录”，再加上 QUIC 使用的是 TLS 1.3，因此仅需 1 个 RTT 就可以「同时」完成建立连接与密钥协商，甚至在第二次连接的时候，应用数据包可以和 QUIC 握手信息（连接信息 + TLS 信息）一起发送，达到 0-RTT 的效果。

如下图右边部分，HTTP/3 当会话恢复时，有效负载数据与第一个数据包一起发送，可以做到 0-RTT：

![HTTP/3](https://camo.githubusercontent.com/c10cd44d6a90ef3190b4cb138dd18303c8035476eff7b2976bccb336a0797610/68747470733a2f2f63646e2e7869616f6c696e636f64696e672e636f6d2f67682f7869616f6c696e636f6465722f496d616765486f737434406d61696e2f2545372542442539312545372542422539432f68747470332f302d7274742e676966)

#### 连接迁移

当移动设备的网络从 4G 切换到 WiFi 时，意味着 IP 地址变化了，那么就必须要断开连接，然后重新建立连接，而建立连接的过程包含 TCP 三次握手和 TLS 四次握手的时延，以及 TCP 慢启动的减速过程，给用户的感觉就是网络突然卡顿了一下，因此连接的迁移成本是很高的。

而 QUIC 协议没有用四元组的方式来“绑定”连接，而是通过连接 ID 来标记通信的两个端点，客户端和服务器可以各自选择一组 ID 来标记自己，因此即使移动设备的网络变化后，导致 IP 地址变化了，只要仍保有上下文信息（比如连接 ID、TLS 密钥等），就可以“无缝”地复用原连接，消除重连的成本，没有丝毫卡顿感，达到了连接迁移的功能。

#### 简化帧结构、QPACK 优化头部压缩

HTTP/3 同 HTTP/2 一样采用二进制帧的结构，不同的地方在于 HTTP/2 的二进制帧里需要定义 Stream，而 HTTP/3 自身不需要再定义 Stream，直接使用 QUIC 里的 Stream，于是 HTTP/3 的帧的结构也变简单了。

![HTTP/3帧](https://camo.githubusercontent.com/da7789d070872afc91c65d89c00cb176cd3d1c54241d65b4ac2a3bb72c605412/68747470733a2f2f63646e2e7869616f6c696e636f64696e672e636f6d2f67682f7869616f6c696e636f6465722f496d616765486f737434406d61696e2f2545372542442539312545372542422539432f68747470332f68747470336672616d652e706e67)

根据帧类型的不同，大体上分为数据帧和控制帧两大类，Headers 帧（HTTP 头部）和 DATA 帧（HTTP 包体）属于数据帧。

HTTP/3 在头部压缩算法这一方面也做了升级，升级成了 `QPACK`。与 HTTP/2 中的 HPACK 编码方式相似，HTTP/3 中的 QPACK 也采用了静态表、动态表及 Huffman 编码。

对于静态表的变化，HTTP/2 中的 HPACK 的静态表只有 61 项，而 HTTP/3 中的 QPACK 的静态表扩大到 91 项。

HTTP/2 和 HTTP/3 的 Huffman 编码并没有多大不同，但是动态表编解码方式不同。

所谓的动态表，在首次请求-响应后，双方会将未包含在静态表中的 Header 项（比如一些自定义的 Header）更新进各自的动态表，接着后续传输时仅用 1 个数字表示，然后对方可以根据这 1 个数字从动态表查到对应的数据，就不必每次都传输长长的数据，大大提升了编码效率。

可以看到，`动态表是具有时序性的，如果首次出现的请求Header发生了丢包，后续的请求又遇到这个Header，发送方以为对方已经存进了动态表，于是就将Header压缩了，可对方无法解码出这个 HPACK 头部，因为对方还没建立好动态表，因此后续请求的解码必须阻塞到首次请求中丢失的数据包重传过来才可以正常解码`。

HTTP/3 的 QPACK 解决了这一问题，那它是如何解决的呢？

QUIC 会有两个特殊的单向流，所谓的单向流只有一端可以发送消息，传输 HTTP 消息时用的是双向流，而这两个单向流的用法：

一个叫 QPACK Encoder Stream，用于将一个字典（Key-Value）传递给对方，比如面对不属于静态表的 HTTP 请求头部，客户端可以通过这个 Stream 发送字典；
一个叫 QPACK Decoder Stream，用于响应对方，告诉它刚发的字典已经更新到自己的本地动态表了，后续就可以使用这个字典来编码了。
这两个特殊的单向流是用来`同步双方的动态表`，编码方收到解码方更新确认的通知后，才会使用动态表编码 HTTP 头部。假如动态表的更新消息丢包了，也只会导致某些 Header 不压缩而已，不会阻塞 HTTP 请求。

### HTTP 缓存详解

如果一份网络资源不需要请求，直接从本地缓存拿到，那自然是最快的。http 协议里面定义了缓存机制，其中又分为本地缓存（大家也称它为强缓存）和需要通过请求来验证的缓存（大家也称它为协商缓存）。

#### 本地缓存（强缓存）

在 http1.0 是用`expires`响应头表示返回值的过期时间，浏览器在这个时间之内可以不重新请求直接使用缓存。在 http1.1 之后，改为了`Cache-Control`响应头，从此可以满足更多的缓存要求，里面的`max-age`表示资源在请求 N 秒后过期。注意`max-age`不是浏览器收到响应后经过的时间，它是在源服务器上生成响应后经过的时间，和浏览器时间无关。因此，如果网络上的其他缓存服务器将响应存储 100 秒(使用响应报头字段 Age 表示)，浏览器缓存将从其过期时间中扣除 100 秒。当缓存过期后（我们忽略 stale-while-revalidate、max-stale 等的影响），浏览器会发起条件请求验证资源是否更新（也称协商缓存）。

#### 条件请求（协商缓存）

请求头会有`If-Modified-Since`和`If-None-Match`字段，它们分别是上次请求响应头里的`Last-Modified`和`etag`。`Last-Modified`表示资源最后被修改的时间，单位秒。`etag`是特定版本资源的标识（比如对内容 hash 就可以生成一个 etag）。服务器当`If-None-Match`或者`If-Modified-Since`没有变化时会返回 304 状态码的响应，浏览器会认为资源没有更新从而复用本地缓存。由于`Last-Modified`记录的修改时间是秒为单位，如果修改频率发生在 1 秒内就不能准确判断是否更新了，所以`etag`的判断优先级要高于`Last-Modified`。

`Cache-Control`中如果设置`no-cache`会强制不使用强缓存，直接走协商缓存，即 max-age=0。如果设置`no-store`会不使用任何缓存。

浏览器对请求的缓存策略简单来说就是这样，我们可以看出缓存是由响应头和请求头决定的，开发过程中一般已经由网关和浏览器帮我们自动设置好了，如果你有特定需求，可以定制化使用更多`Cache-Control`功能。

#### 完整的 Cache-Control 功能

`Cache-Control`还有更多更细致的缓存控制能力，完整的响应头和请求头含义看下表。

响应头
|名称|含义|
|----|----|
|max-age|max-age 表示资源在请求 N 秒后过期。注意 max-age 不是浏览器收到响应后经过的时间，它是在源服务器上生成响应后经过的时间，和浏览器时间无关|
|s-maxage|响应头特有，作用和 max-age 类似，但是只会被资源共享服务器（如 cdn）使用，如果它存在时将会忽略 max-age|
|no-cache|表示请求可以被缓存，但每次都需要去服务器验证内容是否更新|
|no-store|请求不会以任何形式缓存|
|no-transform|禁止中介服务器转换内容（比如经过某些服务器时会降低画质以减少图片大小，但内容提供者不希望这样）|
|must-revalidate|响应头特有，请求可以被缓存也可以使用强缓存，但缓存过期后必须重新验证更新（因为浏览器允许断线情况下使用过期的缓存），要么重新验证成功，要么返回 504|
|proxy-revalidate|响应头特有，和 must-revalidate 相似，但只能在资源共享服务器（比如 cdn）使用|
|must-understand|响应头特有，只在基于状态码理解缓存需求时才缓存，和 no-store 一起使用可以作为兜底|
|private|响应头特有，只能缓存在私有缓存中，比如浏览器缓存，不会缓存在资源共享服务器（比如 cdn）中|
|public|响应头特有，和 private 相反，需要特定身份的请求不能使用 public，它可能在任何地方被缓存然后被其他用户拿到|
|immutable|响应头特有，缓存内容在有效期内是不会改变的，有效期内不需要有重新验证的协商请求。现代前端应用一般都是名称带 hash 的资源，内容更新 hash 变化后其实已经是另一个请求了，所以请求不变内容也是不变的|
|stale-while-revalidate|响应头特有，当缓存过期后，在 stale-while-revalidate 指定秒数内，后台会重新验证缓存，这段时间内依然可以正常使用本地缓存|
|stale-if-error|当缓存过期后，在 stale-if-error 指定秒数内，请求发生 500, 502, 503, 504 错误时（不管是服务器产生的还是本地产生的）可以使用本地缓存|

请求头（仅列举响应头没有的）
|max-stale|缓存过期不超过 max-stale 秒时依然可用|
|min-fresh|要求缓存服务返回 min-fresh 秒时间内的新鲜缓存数据，否则就不使用本地缓存|
|only-if-cached|浏览器要求仅在缓存服务器缓存了目标资源的情况下才返回|

## 更『厉害』的缓存：Service Worker

上面讲到的 HTTP 缓存控制权主要还是在后端，而且如果缓存过期了，虽然有协商缓存，但多多少少还是有请求时延的，而且必须要有网络，这不是前端真正理想的本地缓存。那么有没有什么办法能让前端彻底的控制缓存策略，无论是静态资源还是 api 接口通通都可以由前端自己来决定，甚至可以把网页像 App 一样变成一个彻底的本地应用。这就是接下来要讲到的`Service Worker`，让我们看看它有哪些特性。

### 离线缓存

`Service Worker`可以看作是应用与网络请求之间的代理，它可以拦截请求，基于网络是否可用或者其他自定义逻辑来采取合适的行为。举个例子，你可以在应用第一次打开后，将 html、css、js、图片等资源都缓存起来，下一次打开网页时拦截请求并直接返回缓存，这样你的应用离线也可以打开了。如果后来设备联网了，你可以在后台请求最新资源并判断是否更新了，如果更新了你可以提醒用户刷新升级。在启动上，使用 Service Worker 的前端应用完全可以不需要网络，就像客户端 App 一样。

### 推送通知

Service Worker 除了代理请求外，还可以主动让浏览器发出通知，就像 App 的通知一样。你可以使用这个功能做『用户召回』、『热门通知』等。

### 禁止项

我们的主 js 代码是在渲染线程执行的，而 Service Worker 运行在另一个 worker 线程中，所以它不会阻塞主线程，但也导致有些 api 是不能使用的，比如：操作 dom。同时它被设计为完全异步，所以像`XHR`和`Web Storage`这样的同步 api 也是无法使用的，可以用`fetch`请求。动态`import()`也是不可以的，只可以静态 import 模块。

Service Worker 出于安全考虑只能运行在 HTTPS 协议上（用 localhost 可以允许 http），毕竟仅它能够接管请求这一功能就已经很强大了，如果被中间人恶意篡改对于普通用户来说可以做到这个网页永远也无法呈现正确的内容。在 FireFox 中，在无痕模式下也无法使用它。

### 使用方法

Service Worker 的代码应该是一个独立的 js 文件，并且可以通过 https 请求访问，如果你在开发环境，可以允许 http://localhost 这样的地址访问。准备好这些后，首先得在项目代码里注册它：

```js
if ("serviceWorker" in navigator) {
  navigator.serviceWorker.register("/js/service-worker.js", {
    scope: "../",
  });
} else {
  console.log("浏览器不支持Service Worker");
}
```

假设你的网址是`https://www.xxx.com`，同时在`https://www.xxx.com/js/service-worker.js`准备了 Service Worker 的 js，`/js/service-worker.js`实际请求的就是`https://www.xxx.com/js/service-worker.js`。配置里的`scope`表示在什么路径下 Service Worker 生效，如果不设置 scope 默认根目录就生效，网页中任何路径都会使用 Service Worker。按例子中的写法，如果设置`./`则生效路径是`/js/*`，`../`则是根目录。

Service Worker 会经过这 3 个生命周期

1. Download
2. Install
3. Activate

首先是`Download`阶段。当进入一个受 Service Worker 控制的网页时，它会立刻开始下载。如果你之前已经下载过了，那么在这次下载后可能会判断更新，会在以下情况下判断更新：

- 发生了一个在 scope 范围的页面跳转
- Service Worker 内有事件被触发了，同时它在 24 小时内没有下载过

当下载的文件被发现是新的后就会试图安装`Install`，认为是新文件的判断标准是：第一次下载、和旧文件逐字节比较。

如果这是 Service Worker 第一次使用，则尝试安装，然后在成功安装后，将激活`Activate`它。

如果已经有一个旧的 Service Worker 在使用了，会在后台安装，安装完不会激活，这种情况叫做`worker in waiting`。试想一下新旧两个 js 可能逻辑有冲突，旧 js 已经运行过一段时间了，如果直接把旧的替换成新的继续运行网页可能会直接崩溃。

那新 Service Worker 什么时候才会激活使用呢？必须等到所有使用旧 Service Worker 的页面都关闭，新 Service Worker 才会变成`active worker`。你也可以使用`ServiceWorkerGlobalScope.skipWaiting()`直接跳过等待，`Clients.claim()`可以让新 Service Worker 控制当前已经存在的页面（那些使用旧 Service Worker 的页面）。

发生 install、activate 时可以通过监听事件知道，平时用的最多的事件是`FetchEvent`，当页面发起请求时触发，你还可以使用`Cache`缓存数据、使用`FetchEvent.respondWith()`返回你希望的请求返回值。下面给出一段`缓存请求`的常见写法：

```ts
// 缓存版本，可以升级版本让过去的缓存失效
const VERSION = 1;

const shouldCache = (url: string, method: string) => {
  // 你可以自定义shouldCache去控制哪些请求应该缓存
  return true;
};

// 监听每个请求
self.addEventListener("fetch", async (event) => {
  const { url, method } = event.request;
  event.respondWith(
    shouldCache(url, method)
      ? caches
          // 查找缓存
          .match(event.request)
          .then(async (cacheRes) => {
            if (cacheRes) {
              return cacheRes;
            }
            const awaitFetch = fetch(event.request);
            const awaitCaches = caches.open(VERSION);
            const response = await awaitFetch;
            const cache = await awaitCaches;
            // 放进缓存
            cache.put(event.request, response.clone());
            return response;
          })
          .catch(() => {
            return fetch(event.request);
          })
      : fetch(event.request)
  );
});
```

上面的代码缓存建立后就不会再更新了，如果你的内容是可能变化的，担心缓存会不新鲜，你可以先返回缓存，以保证用户最快看到内容，然后在 Service Worker 后台请求最新数据，更新到缓存里，最后通知主线程告诉用户有内容更新了，让用户自己决定是否要升级应用。后台请求、判断更新的代码可以自己试着写一下，这里主要讲一讲 Service Worker 如何告诉主线程请求的内容更新了，两个线程之间该如何通信呢？

### 如何与主线程通信

我们可以创建一个消息频道`MessageChannel`，它有两个端口，可以独立收发消息，将其中一个端口`port2`交给 Service Worker，`port1`端口留在主线程，它们就可以通信了。下面的代码将简单展示如何让两个线程互相通信，从而做到`『查看worker线程log』`、`『通知内容更新』`、`『升级应用』`功能。

**主线程里的代码**

```ts
const messageChannel = new MessageChannel();

// 将port2交给控制当前页面的那个Service Worker
navigator.serviceWorker.controller.postMessage(
  // "messageChannelConnection"是自定义的，用来区分消息类型
  { type: "messageChannelConnection" },
  [messageChannel.port2]
);

messageChannel.port1.onmessage = (message) => {
  // 你可以自定义消息格式来满足不同业务
  if (typeof message.data === "string") {
    // 可以打印来自worker线程的日志
    console.log("from service worker message:", message.data);
  } else if (message.data && typeof message.data === "object") {
    switch (message.data.classification) {
      case "content-update":
        // 你可以自定义不同的消息类型，来做出不同的UI表现，比如『通知用户更新』
        alert("有新内容哦，你可以刷新页面查看");
        break;
      default:
        break;
    }
  }
};
```

**Service Worker 里的代码**

```ts
let messageChannelPort: MessagePort;

self.addEventListener("message", onMessage);

// 收到消息
const onMessage = (event: ExtendableMessageEvent) => {
  if (event.data && event.data.type === "messageChannelConnection") {
    // 拿到了port2保存起来
    messageChannelPort = event.ports[0];
  } else if (event.data && event.data.type === "skip-waiting") {
    // 如果主线程发出了"skip-waiting"消息，这里就会直接更新Service Worker，也就让应用升级了。
    self.skipWaiting();
  }
};

// 发送消息
const postMessage = (message: any) => {
  if (messageChannelPort) {
    messageChannelPort.postMessage(message);
  }
};
```
